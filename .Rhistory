Z
}, simplify = FALSE)
}
m <- 1
Z_train <- simulate(theta_train, m)
Z_val   <- simulate(theta_val, m)
prior <- function(K) {
b0 <- runif(K, min = 0, max = 10)
b1 <- rnorm(K)
theta <- matrix(c(b1, b1), byrow = TRUE, ncol = K)
return(theta)
}
theta_train = prior(10000)
theta_val   = prior(2000)
simulate <- function(theta_set, m) {
n <- 50 # number of observations in each replicate
X <- seq(0, 1, length.out = n)
apply(theta_set, 2, function(theta) {
e <- rnorm(n)
Z <- theta[1] + theta[2] * X + e
dim(Z) <- c(n, 1, m)
Z
}, simplify = FALSE)
}
m <- 1
Z_train <- simulate(theta_train, m)
Z_val   <- simulate(theta_val, m)
estimator <- juliaEval('
n = 50   # size of each replicate
w = 128   # number of neurons in each layer
p = 2    # number of parameters in the statistical model
using Flux
psi = Chain(Dense(n, w, relu), Dense(w, w, relu), Dense(w, w, relu))
phi = Chain(Dense(w, w, relu), Dense(w, w, relu), Dense(w, p), Flux.flatten)
using NeuralEstimators
estimator = DeepSet(psi, phi)
')
estimator <- juliaEval('
n = 50   # size of each replicate
w = 64   # number of neurons in each layer
p = 2    # number of parameters in the statistical model
using Flux
psi = Chain(Dense(n, w, relu), Dense(w, w, relu), Dense(w, w, relu))
phi = Chain(Dense(w, w, relu), Dense(w, w, relu), Dense(w, p), Flux.flatten)
using NeuralEstimators
estimator = DeepSet(psi, phi)
')
estimator <- train(
estimator,
theta_train = theta_train,
theta_val   = theta_val,
Z_train = Z_train,
Z_val   = Z_val,
epochs = 50L
)
J     <- 300
theta <- as.matrix(c(3, 0.5))
Z <- simulate(theta, m) # pretend that this is observed data
estimate(estimator, Z)
Z
plot(Z)
plot(Z[1])
plot(Z[[1]])
b <- 0.5
simulate <- function(theta_set, m) {
n <- 50 # number of observations in each replicate
X <- seq(0, 10, length.out = n)
apply(theta_set, 2, function(theta) {
e <- rnorm(n)
Z <- theta[1] + theta[2] * X + e
dim(Z) <- c(n, 1, m)
Z
}, simplify = FALSE)
}
m <- 1
Z_train <- simulate(theta_train, m)
Z_val   <- simulate(theta_val, m)
plot(Z_train[[1]])
simulate <- function(theta_set, m) {
n <- 50 # number of observations in each replicate
X <- seq(0, 10, length.out = n)
apply(theta_set, 2, function(theta) {
e <- rnorm(n, sd = 0.05)
Z <- theta[1] + theta[2] * X + e
dim(Z) <- c(n, 1, m)
Z
}, simplify = FALSE)
}
m <- 1
Z_train <- simulate(theta_train, m)
Z_val   <- simulate(theta_val, m)
plot(Z_train[[1]])
plot(Z_train[[2]])
plot(Z_train[[3]])
estimator <- juliaEval('
n = 50   # size of each replicate
w = 64   # number of neurons in each layer
p = 2    # number of parameters in the statistical model
using Flux
psi = Chain(Dense(n, w, relu), Dense(w, w, relu), Dense(w, w, relu))
phi = Chain(Dense(w, w, relu), Dense(w, w, relu), Dense(w, p), Flux.flatten)
using NeuralEstimators
estimator = DeepSet(psi, phi)
')
estimator <- train(
estimator,
theta_train = theta_train,
theta_val   = theta_val,
Z_train = Z_train,
Z_val   = Z_val,
epochs = 50L
)
J     <- 300
theta <- as.matrix(c(3, 0.5))
Z <- simulate(theta, m) # pretend that this is observed data
plot(Z[[1]])
estimate(estimator, Z)
theta <- as.matrix(c(1, 0.5))
Z <- simulate(theta, m) # pretend that this is observed data
plot(Z[[1]])
estimate(estimator, Z)
theta_train
theta_train[, 1:10]
prior <- function(K) {
b0 <- runif(K, min = 0, max = 10)
b1 <- rnorm(K)
theta <- matrix(c(b0, b1), byrow = TRUE, ncol = K)
return(theta)
}
theta_train = prior(10000)
theta_val   = prior(2000)
theta_train[, 1:10]
simulate <- function(theta_set, m) {
n <- 50 # number of observations in each replicate
X <- seq(0, 10, length.out = n)
apply(theta_set, 2, function(theta) {
e <- rnorm(n, sd = 0.05)
Z <- theta[1] + theta[2] * X + e
dim(Z) <- c(n, 1, m)
Z
}, simplify = FALSE)
}
m <- 1
Z_train <- simulate(theta_train, m)
Z_val   <- simulate(theta_val, m)
plot(Z_train[[1]])
plot(Z_train[[2]])
plot(Z_train[[3]])
estimator <- juliaEval('
n = 50   # size of each replicate
w = 64   # number of neurons in each layer
p = 2    # number of parameters in the statistical model
using Flux
psi = Chain(Dense(n, w, relu), Dense(w, w, relu), Dense(w, w, relu))
phi = Chain(Dense(w, w, relu), Dense(w, w, relu), Dense(w, p), Flux.flatten)
using NeuralEstimators
estimator = DeepSet(psi, phi)
')
estimator <- train(
estimator,
theta_train = theta_train,
theta_val   = theta_val,
Z_train = Z_train,
Z_val   = Z_val,
epochs = 50L
)
J     <- 300
theta <- as.matrix(c(1, 0.5))
Z <- simulate(theta, m) # pretend that this is observed data
plot(Z[[1]])
estimate(estimator, Z)
Z
X
X <- seq(0, 10, length.out = n)
X <- seq(0, 10, length.out = n)
plot(X, Z[[1]])
# want the endpoint of the curve to match that of the line: exp(a * X[n]) = Z[n] => a = ln(Z[n])/X[n]
a <- ln(Z[[1]][n])/X[n]
# want the endpoint of the curve to match that of the line: exp(a * X[n]) = Z[n] => a = ln(Z[n])/X[n]
a <- log(Z[[1]][n])/X[n]
a
Z2 <- exp(a * X)
Z2
lines(X, Z2, col = "red")
plot(X, Z[[1]])
points(X, Z2, col = "red")
J     <- 300
theta <- as.matrix(c(1, 2))
Z <- simulate(theta, m)
X <- seq(0, 10, length.out = n)
plot(X, Z[[1]])
estimate(estimator, Z)
plot(X, Z[[1]], ylab = "Z")
estimate(estimator, Z)
thetahat <- estimate(estimator, Z)
thetahat[1]
thetahat[1] + thetahat[2] * X
yhat <- thetahat[1] + thetahat[2] * X
lines(X, yhat)
lines(X, yhat, col = "red")
lines(X, yhat)
# want the endpoint of the curve to match that of the line: exp(a * X[n]) = Z[n] => a = log(Z[n])/X[n]
a <- log(Z[[1]][n])/X[n]
Z2 <- exp(a * X)
points(X, Z2, col = "red")
class(Z)
c(n, 1, m)
dim(Z2) <- c(n, 1, m)
thetahat2 <- estimate(estimator, Z2)
Z2 <- list(Z2)
thetahat2 <- estimate(estimator, Z2)
thetahat2
yhat2 <- thetahat2[1] + thetahat2[2] * X
lines(X, yhat2, col = "red")
list(plot(X, Z[[1]], ylab = "Z"), plot(X, Z[[1]], ylab = "Z"), plot(X, Z[[1]], ylab = "Z"))
x <- list(plot(X, Z[[1]], ylab = "Z"), plot(X, Z[[1]], ylab = "Z"), plot(X, Z[[1]], ylab = "Z"))
x[[1]]
x <- list(plot(X, Z[[1]], ylab = "Z"), plot(X, Z[[1]], ylab = "x"), plot(X, Z[[1]], ylab = "Z"))
x[[1]]
x[[2]]
x <- list(plot(X, Z[[1]], ylab = "Z"), plot(X, Z[[1]], ylab = "x"), plot(X, Z[[1]], ylab = "Z"))
x[[2]]
x <- list(plot(X, Z[[1]], ylab = "Z"), plot(X, Z[[1]], ylab = "x"), plot(X, Z[[1]], ylab = "x"))
x[[2]]
par(mfrow = c(2, 3))
thetalist <- prior(6)
thetalist
theta_test <- prior(6)
apply(theta_test, 2, function(theta) {
Z     <- simulate(theta, m)
thetahat <- estimate(estimator, Z)
yhat     <- thetahat[1] + thetahat[2] * X
plot(X, Z[[1]], ylab = "Z")
lines(X, yhat)
# want the endpoint of the curve to match that of the line: exp(a * X[n]) = Z[n] => a = log(Z[n])/X[n]
a <- log(Z[[1]][n])/X[n]
Z2 <- exp(a * X)
dim(Z2) <- c(n, 1, m)
Z2 <- list(Z2)
thetahat2 <- estimate(estimator, Z2)
yhat2 <- thetahat2[1] + thetahat2[2] * X
points(X, Z2, col = "red")
lines(X, yhat2, col = "red")
})
theta_test <- prior(6)
theta_test
apply(theta_test, 2, function(theta) {
theta <- as.matrix(theta)
Z     <- simulate(theta, m)
thetahat <- estimate(estimator, Z)
yhat     <- thetahat[1] + thetahat[2] * X
plot(X, Z[[1]], ylab = "Z")
lines(X, yhat)
# want the endpoint of the curve to match that of the line: exp(a * X[n]) = Z[n] => a = log(Z[n])/X[n]
a <- log(Z[[1]][n])/X[n]
Z2 <- exp(a * X)
dim(Z2) <- c(n, 1, m)
Z2 <- list(Z2)
thetahat2 <- estimate(estimator, Z2)
yhat2 <- thetahat2[1] + thetahat2[2] * X
points(X, Z2, col = "red")
lines(X, yhat2, col = "red")
})
apply(theta_test, 2, function(theta) {
browser()
theta <- as.matrix(theta)
Z     <- simulate(theta, m)
thetahat <- estimate(estimator, Z)
yhat     <- thetahat[1] + thetahat[2] * X
plot(X, Z[[1]], ylab = "Z")
lines(X, yhat)
# want the endpoint of the curve to match that of the line: exp(a * X[n]) = Z[n] => a = log(Z[n])/X[n]
a <- log(Z[[1]][n])/X[n]
Z2 <- exp(a * X)
dim(Z2) <- c(n, 1, m)
Z2 <- list(Z2)
thetahat2 <- estimate(estimator, Z2)
yhat2 <- thetahat2[1] + thetahat2[2] * X
points(X, Z2, col = "red")
lines(X, yhat2, col = "red")
})
theta <- as.matrix(theta)
Z     <- simulate(theta, m)
thetahat <- estimate(estimator, Z)
yhat     <- thetahat[1] + thetahat[2] * X
plot(X, Z[[1]], ylab = "Z")
lines(X, yhat)
# want the endpoint of the curve to match that of the line: exp(a * X[n]) = Z[n] => a = log(Z[n])/X[n]
a <- log(Z[[1]][n])/X[n]
a
Z2 <- exp(a * X)
dim(Z2) <- c(n, 1, m)
Z2 <- list(Z2)
thetahat2 <- estimate(estimator, Z2)
yhat2 <- thetahat2[1] + thetahat2[2] * X
yhat2
points(X, Z2, col = "red")
X
Z2
par(mfrow = c(2, 3))
apply(theta_test, 2, function(theta) {
browser()
theta <- as.matrix(theta)
Z     <- simulate(theta, m)
thetahat <- estimate(estimator, Z)
yhat     <- thetahat[1] + thetahat[2] * X
plot(X, Z[[1]], ylab = "Z")
lines(X, yhat)
# want the endpoint of the curve to match that of the line: exp(a * X[n]) = Z[n] => a = log(Z[n])/X[n]
a <- log(Z[[1]][n])/X[n]
Z2 <- exp(a * X)
dim(Z2) <- c(n, 1, m)
Z2 <- list(Z2)
thetahat2 <- estimate(estimator, Z2)
yhat2 <- thetahat2[1] + thetahat2[2] * X
points(X, Z2[[1]], col = "red")
lines(X, yhat2, col = "red")
})
apply(theta_test, 2, function(theta) {
theta <- as.matrix(theta)
Z     <- simulate(theta, m)
thetahat <- estimate(estimator, Z)
yhat     <- thetahat[1] + thetahat[2] * X
plot(X, Z[[1]], ylab = "Z")
lines(X, yhat)
# want the endpoint of the curve to match that of the line: exp(a * X[n]) = Z[n] => a = log(Z[n])/X[n]
a <- log(Z[[1]][n])/X[n]
Z2 <- exp(a * X)
dim(Z2) <- c(n, 1, m)
Z2 <- list(Z2)
thetahat2 <- estimate(estimator, Z2)
yhat2 <- thetahat2[1] + thetahat2[2] * X
points(X, Z2[[1]], col = "red")
lines(X, yhat2, col = "red")
})
prior <- function(K) {
b0 <- runif(K, min = 5, max = 15)
b1 <- runif(K, min = 0, max = 5)
theta <- matrix(c(b0, b1), byrow = TRUE, ncol = K)
return(theta)
}
theta_train = prior(10000)
theta_val   = prior(2000)
n <- 50 # number of observations in each replicate
X <- seq(0, 10, length.out = n)
simulate <- function(theta_set, m) {
apply(theta_set, 2, function(theta) {
e <- rnorm(n, sd = 0.05)
Z <- theta[1] + theta[2] * X + e
dim(Z) <- c(n, 1, m)
Z
}, simplify = FALSE)
}
m <- 1
Z_train <- simulate(theta_train, m)
Z_val   <- simulate(theta_val, m)
plot(Z_train[[1]])
plot(Z_train[[2]])
plot(Z_train[[3]])
plot(X, Z_train[[1]])
plot(X, Z_train[[2]])
plot(X, Z_train[[3]])
X <- seq(0, 5, length.out = n)
simulate <- function(theta_set, m) {
apply(theta_set, 2, function(theta) {
e <- rnorm(n, sd = 0.05)
Z <- theta[1] + theta[2] * X + e
dim(Z) <- c(n, 1, m)
Z
}, simplify = FALSE)
}
m <- 1
Z_train <- simulate(theta_train, m)
Z_train <- simulate(theta_train, m)
Z_val   <- simulate(theta_val, m)
plot(X, Z_train[[1]])
plot(X, Z_train[[2]])
plot(X, Z_train[[3]])
estimator <- juliaLet('
w = 64   # number of neurons in each layer
using Flux
psi = Chain(Dense(n, w, relu), Dense(w, w, relu), Dense(w, w, relu))
phi = Chain(Dense(w, w, relu), Dense(w, w, relu), Dense(w, p), Flux.flatten)
using NeuralEstimators
estimator = DeepSet(psi, phi)
', n = n, p = nrow(theta_train))
estimator <- juliaEval('
n = 50   # size of each replicate
w = 64   # number of neurons in each layer
p = 2    # number of parameters in the statistical model
using Flux
psi = Chain(Dense(n, w, relu), Dense(w, w, relu), Dense(w, w, relu))
phi = Chain(Dense(w, w, relu), Dense(w, w, relu), Dense(w, p), Flux.flatten)
using NeuralEstimators
estimator = DeepSet(psi, phi)
')
estimator <- train(
estimator,
theta_train = theta_train,
theta_val   = theta_val,
Z_train = Z_train,
Z_val   = Z_val,
epochs = 50L
)
par(mfrow = c(2, 3))
theta_test <- prior(6)
apply(theta_test, 2, function(theta) {
theta <- as.matrix(theta)
Z     <- simulate(theta, m)
thetahat <- estimate(estimator, Z)
yhat     <- thetahat[1] + thetahat[2] * X
plot(X, Z[[1]], ylab = "Z")
lines(X, yhat)
# want the endpoint of the curve to match that of the line: exp(a * X[n]) = Z[n] => a = log(Z[n])/X[n]
a <- log(Z[[1]][n])/X[n]
Z2 <- exp(a * X)
dim(Z2) <- c(n, 1, m)
Z2 <- list(Z2)
thetahat2 <- estimate(estimator, Z2)
yhat2 <- thetahat2[1] + thetahat2[2] * X
points(X, Z2[[1]], col = "red")
lines(X, yhat2, col = "red")
})
par(mfrow = c(2, 3))
theta_test <- prior(6)
apply(theta_test, 2, function(theta) {
theta <- as.matrix(theta)
Z     <- simulate(theta, m)
thetahat <- estimate(estimator, Z)
yhat     <- thetahat[1] + thetahat[2] * X
Z <- Z[[1]] # unlist for convenience
plot(X, Z, ylab = "Z")
lines(X, yhat)
# want the endpoints of the curve to match that of the line, so we solve:
# aexp(b * X[n]) = Z[n]
# aexp(b * X[1]) = Z[1]
# since X[1] = 0, we have a = Z[1], and we then have b = log(Z[n]/a)/X[n]
a <- Z[1]
b <- log(Z[n]/a)/X[n]
Z2 <- a * exp(b * X)
dim(Z2) <- c(n, 1, m)
Z2 <- list(Z2)
thetahat2 <- estimate(estimator, Z2)
yhat2 <- thetahat2[1] + thetahat2[2] * X
points(X, Z2[[1]], col = "red")
lines(X, yhat2, col = "red")
})
n <- 50 # number of observations in each replicate
X <- seq(0, 1, length.out = n)
simulate <- function(theta_set, m) {
apply(theta_set, 2, function(theta) {
e <- rnorm(n, sd = 0.05)
Z <- theta[1] + theta[2] * X + e
dim(Z) <- c(n, 1, m)
Z
}, simplify = FALSE)
}
m <- 1
Z_train <- simulate(theta_train, m)
Z_val   <- simulate(theta_val, m)
plot(X, Z_train[[1]])
plot(X, Z_train[[2]])
plot(X, Z_train[[3]])
prior <- function(K) {
b0 <- runif(K, min = 1, max = 5)
b1 <- runif(K, min = 0, max = 5)
theta <- matrix(c(b0, b1), byrow = TRUE, ncol = K)
return(theta)
}
theta_train = prior(10000)
theta_val   = prior(2000)
n <- 50 # number of observations in each replicate
X <- seq(0, 1, length.out = n)
simulate <- function(theta_set, m) {
apply(theta_set, 2, function(theta) {
e <- rnorm(n, sd = 0.05)
Z <- theta[1] + theta[2] * X + e
dim(Z) <- c(n, 1, m)
Z
}, simplify = FALSE)
}
m <- 1
Z_train <- simulate(theta_train, m)
Z_val   <- simulate(theta_val, m)
plot(X, Z_train[[1]])
plot(X, Z_train[[2]])
plot(X, Z_train[[3]])
par(mfrow = c(2, 3))
theta_test <- prior(6)
apply(theta_test, 2, function(theta) {
theta <- as.matrix(theta)
Z     <- simulate(theta, m)
thetahat <- estimate(estimator, Z)
yhat     <- thetahat[1] + thetahat[2] * X
Z <- Z[[1]] # unlist for convenience
plot(X, Z, ylab = "Z")
lines(X, yhat)
# want the endpoints of the curve to match that of the line, so we solve:
# aexp(b * X[n]) = Z[n]
# aexp(b * X[1]) = Z[1]
# since X[1] = 0, we have a = Z[1], and we then have b = log(Z[n]/a)/X[n]
a <- Z[1]
b <- log(Z[n]/a)/X[n]
Z2 <- a * exp(b * X)
dim(Z2) <- c(n, 1, m)
Z2 <- list(Z2)
thetahat2 <- estimate(estimator, Z2)
yhat2 <- thetahat2[1] + thetahat2[2] * X
points(X, Z2[[1]], col = "red")
lines(X, yhat2, col = "red")
})
devtools::build(vignettes = F)
